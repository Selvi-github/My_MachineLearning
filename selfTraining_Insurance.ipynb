{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "dmnnkBCSz-3R",
        "outputId": "f31d3fcf-c815-4d36-cc20-a0d9237a1ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d4f829cc1e0ca63d9e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d4f829cc1e0ca63d9e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# 1. Install Gradio\n",
        "!pip install gradio --quiet\n",
        "\n",
        "# 2. Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.semi_supervised import SelfTrainingClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 3. Load and preprocess the dataset\n",
        "def load_data():\n",
        "    df = pd.read_csv(\"/content/insurance_customer_data (1).csv\")\n",
        "    features = df[['Age', 'Annual_Premium', 'Vintage']]\n",
        "    target = df['Response']\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(target)\n",
        "    return features, y_encoded, le\n",
        "\n",
        "# 4. Train Self-Training model\n",
        "def train_self_training(X, y):\n",
        "    # Split into labeled and unlabeled\n",
        "    X_labeled, X_unlabeled, y_labeled, _ = train_test_split(\n",
        "        X, y, train_size=0.2, stratify=y, random_state=42\n",
        "    )\n",
        "\n",
        "    y_combined = np.concatenate([y_labeled, [-1]*len(X_unlabeled)])\n",
        "    X_combined = pd.concat([X_labeled, X_unlabeled])\n",
        "\n",
        "    base_clf = LogisticRegression(max_iter=1000)\n",
        "    self_training = SelfTrainingClassifier(base_clf, threshold=0.8, verbose=False)\n",
        "    self_training.fit(X_combined, y_combined)\n",
        "\n",
        "    return self_training\n",
        "\n",
        "# Load and train model initially\n",
        "X_full, y_full, label_encoder = load_data()\n",
        "model = train_self_training(X_full, y_full)\n",
        "\n",
        "# 5. Prediction function\n",
        "def predict(age, premium, vintage):\n",
        "    input_data = pd.DataFrame([[age, premium, vintage]], columns=['Age', 'Annual_Premium', 'Vintage'])\n",
        "    pred = model.predict(input_data)[0]\n",
        "    label = label_encoder.inverse_transform([pred])[0]\n",
        "    return f\"üß† Predicted Response: {label}\"\n",
        "\n",
        "# 6. Retrain function (simulate self-learning loop)\n",
        "def retrain_model():\n",
        "    global model\n",
        "    model = train_self_training(X_full, y_full)\n",
        "    return \"‚úÖ Model retrained with self-labeled data.\"\n",
        "\n",
        "# 7. Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üõ°Ô∏è Insurance Customer Prediction (Self-Learning ML)\")\n",
        "    with gr.Row():\n",
        "        age = gr.Number(label=\"Customer Age\", value=35)\n",
        "        premium = gr.Number(label=\"Annual Premium\", value=30000)\n",
        "        vintage = gr.Number(label=\"Vintage (Days as Customer)\", value=100)\n",
        "\n",
        "    predict_btn = gr.Button(\"üîç Predict Response\")\n",
        "    output = gr.Textbox(label=\"Prediction Result\")\n",
        "\n",
        "    retrain_btn = gr.Button(\"üîÅ Retrain Model\")\n",
        "\n",
        "    predict_btn.click(predict, inputs=[age, premium, vintage], outputs=output)\n",
        "    retrain_btn.click(retrain_model, outputs=output)\n",
        "\n",
        "demo.launch()\n"
      ]
    }
  ]
}